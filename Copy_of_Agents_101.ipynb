{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arksolutionzz/ark/blob/master/Copy_of_Agents_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini LLM Connection"
      ],
      "metadata": {
        "id": "QAs1h5OLThnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FpBW4nfpSiqe",
        "outputId": "439afe80-c03e-409b-89c3-adb2b1cda265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-gemini\n",
            "  Downloading llama_index_llms_gemini-0.1.11-py3-none-any.whl.metadata (735 bytes)\n",
            "Collecting google-generativeai<0.6.0,>=0.5.2 (from llama-index-llms-gemini)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.11.post1 (from llama-index-llms-gemini)\n",
            "  Downloading llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pillow<11.0.0,>=10.2.0 (from llama-index-llms-gemini)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.4 (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini)\n",
            "  Downloading google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.26.4)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.31.0)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (4.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.63.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.2.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (24.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.16.0)\n",
            "Downloading llama_index_llms_gemini-0.1.11-py3-none-any.whl (4.9 kB)\n",
            "Downloading google_generativeai-0.5.4-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dirtyjson, tenacity, pillow, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, google-ai-generativelanguage, google-generativeai, llama-index-llms-gemini\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.6\n",
            "    Uninstalling google-ai-generativelanguage-0.6.6:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.6\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.7.2\n",
            "    Uninstalling google-generativeai-0.7.2:\n",
            "      Successfully uninstalled google-generativeai-0.7.2\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 google-ai-generativelanguage-0.6.4 google-generativeai-0.5.4 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-core-0.10.59 llama-index-llms-gemini-0.1.11 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.37.1 pillow-10.4.0 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google"
                ]
              },
              "id": "d01cf7d68e174f52b77b9cca0ed5ed80"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install llama-index-llms-gemini"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env GOOGLE_API_KEY=AIzaSyA3IXv5kFK-xxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYAftAjrSoM-",
        "outputId": "15f7b33e-863f-4bc4-a2e5-e9ceb1fb1a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=AIzaSyA3IXv5kFK-JS4osq3GYQkEMUlmmkDz9oo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic LLM Call"
      ],
      "metadata": {
        "id": "U2MNFH_FTlsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "llm = Gemini(model = 'models/gemini-1.5-flash')\n",
        "result = llm.complete(\n",
        "    \"Write a peom about Agents workshop on a bright sunny Friday\"\n",
        ")"
      ],
      "metadata": {
        "id": "EAkmhXyFS5h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV2E-FdFTNsb",
        "outputId": "716f6f14-50e2-436b-a087-9e3101e8232b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sunbeams dance, a golden hue,\n",
            "Upon the workshop, bright and new.\n",
            "It's Friday's dawn, a day for cheer,\n",
            "As agents gather, drawing near.\n",
            "\n",
            "With laptops open, minds alight,\n",
            "They delve into tasks, day and night.\n",
            "From data mining to code they write,\n",
            "Their skills honed sharp, a brilliant sight.\n",
            "\n",
            "The air is buzzing, filled with talk,\n",
            "Of strategies, plans, and walk.\n",
            "Through challenges, they'll find their way,\n",
            "To solve the puzzles, come what may.\n",
            "\n",
            "The coffee flows, a constant stream,\n",
            "Fueling minds, a vibrant dream.\n",
            "Collaboration, a key they hold,\n",
            "As stories unfold, both new and old.\n",
            "\n",
            "The workshop hums, a vibrant hive,\n",
            "Where agents thrive, and dreams survive.\n",
            "With every click, a step they take,\n",
            "To shape the future, for goodness sake.\n",
            "\n",
            "So raise a glass, to Friday's light,\n",
            "And to the agents, shining bright.\n",
            "May their work bring joy and peace,\n",
            "And may their efforts never cease. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct Agent"
      ],
      "metadata": {
        "id": "uzg3jDAiTnMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.parse\n"
      ],
      "metadata": {
        "id": "6PJ9qXndTbID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
      ],
      "metadata": {
        "id": "9vHOdDV8TuAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "add_tool = FunctionTool.from_defaults(fn=add)"
      ],
      "metadata": {
        "id": "H6NYeQU3TvuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = llm = Gemini(model = 'models/gemini-1.5-flash')\n",
        "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "4ReWIUDATwjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is 4 * 4 + 2\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "la5a7Dy4T3tz",
        "outputId": "84d6d6b7-7fd4-4852-9e42-bc7ed874dbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 708dd9db-c3a4-437b-8f20-ca29d3834643. Step input: What is 4 * 4 + 2\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: multiply\n",
            "Action Input: {'a': 4, 'b': 4}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 16\n",
            "\u001b[0m> Running step e2cd4939-8969-4bd6-baf6-734d30e22b00. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: add\n",
            "Action Input: {'a': 16, 'b': 2}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 18\n",
            "\u001b[0m> Running step c3da1b41-6d01-4140-af64-afa18ceefc0b. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: 18\n",
            "\u001b[0m18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_dict = agent.get_prompts()\n",
        "for k, v in prompt_dict.items():\n",
        "    print(f\"Prompt: {k}\\n\\nValue: {v.template}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys9X3KieT85B",
        "outputId": "2139f488-9837-4f7f-821c-36f41fb97af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: agent_worker:system_prompt\n",
            "\n",
            "Value: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
            "\n",
            "## Tools\n",
            "\n",
            "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
            "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
            "\n",
            "You have access to the following tools:\n",
            "{tool_desc}\n",
            "\n",
            "\n",
            "## Output Format\n",
            "\n",
            "Please answer in the same language as the question and use the following format:\n",
            "\n",
            "```\n",
            "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
            "Action: tool name (one of {tool_names}) if using a tool.\n",
            "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
            "```\n",
            "\n",
            "Please ALWAYS start with a Thought.\n",
            "\n",
            "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
            "\n",
            "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
            "\n",
            "If this format is used, the user will respond in the following format:\n",
            "\n",
            "```\n",
            "Observation: tool response\n",
            "```\n",
            "\n",
            "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
            "\n",
            "```\n",
            "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: [your answer here (In the same language as the user's question)]\n",
            "```\n",
            "\n",
            "```\n",
            "Thought: I cannot answer the question with the provided tools.\n",
            "Answer: [your answer here (In the same language as the user's question)]\n",
            "```\n",
            "\n",
            "## Current Conversation\n",
            "\n",
            "Below is the current conversation consisting of interleaving human and assistant messages.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Tool"
      ],
      "metadata": {
        "id": "sz2wM4vqVHRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duckduckgo_search(query: str, num_results: int = 5) -> str:\n",
        "    \"\"\"Perform a DuckDuckGo search and return the results\"\"\"\n",
        "    encoded_query = urllib.parse.quote(query)\n",
        "    url = f\"https://html.duckduckgo.com/html/?q={encoded_query}\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    results = []\n",
        "    for result in soup.find_all('div', class_='result__body')[:num_results]:\n",
        "        title = result.find('h2', class_='result__title').text.strip()\n",
        "        snippet = result.find('a', class_='result__snippet').text.strip()\n",
        "        results.append(f\"Title: {title}\\nSnippet: {snippet}\\n\")\n",
        "\n",
        "    return \"\\n\".join(results) if results else \"No results found.\""
      ],
      "metadata": {
        "id": "GOGmsDbCfqX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "duckduckgo_tool = FunctionTool.from_defaults(fn=duckduckgo_search)\n",
        "\n",
        "llm = Gemini(model='models/gemini-1.5-flash')\n",
        "agent = ReActAgent.from_tools([multiply_tool, duckduckgo_tool], llm=llm, verbose=True)\n",
        "\n",
        "# Example usage\n",
        "response = agent.chat(\"What is the capital of France and what's its population multiplied by 2?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "rYGS7S7Fff6Y",
        "outputId": "2216b213-b824-4e9c-d294-d8a6021fea33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 53d5bb3e-13c4-4f24-bb65-9f1cbc5ba004. Step input: What is the capital of France and what's its population multiplied by 2?\n",
            "\u001b[1;3;38;5;200mThought: I need to use a tool to find the capital of France and its population.\n",
            "Action: duckduckgo_search\n",
            "Action Input: {'query': 'capital of France population', 'num_results': 1}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Title: Paris - Wikipedia\n",
            "Snippet: Paris (French pronunciation: ⓘ) is the capital and largest city of France.With an official estimated population of 2,102,650 residents in January 2023 in an area of more than 105 km 2 (41 sq mi), Paris is the fourth-largest city in the European Union and the 30th most densely populated city in the world in 2022. Since the 17th century, Paris has been one of the world's major centres of ...\n",
            "\n",
            "\u001b[0m> Running step a6a2c139-04c9-4d39-abc3-4684e6c29389. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have the population of Paris. I need to use a tool to multiply it by 2.\n",
            "Action: multiply\n",
            "Action Input: {'a': 2102650, 'b': 2}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 4205300\n",
            "\u001b[0m> Running step df3bcaeb-adf7-4855-83a7-13888d1c4fc7. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: The capital of France is Paris and its population multiplied by 2 is 4,205,300.\n",
            "\u001b[0mThe capital of France is Paris and its population multiplied by 2 is 4,205,300.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Step up - Multi Agent System"
      ],
      "metadata": {
        "id": "xpXge5ZScNkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q crewai\n",
        "!pip install --q -U duckduckgo-search\n",
        "!pip install --q langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mPgBz1tVrmB",
        "outputId": "314cd282-c9d7-47a3-c6b5-96f423dec27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.3/209.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.8/379.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-llms-gemini 0.1.11 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.7.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process"
      ],
      "metadata": {
        "id": "NSbWdig9cQAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set gemini flash as llm\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             verbose = True,\n",
        "                             temperature = 0.6,\n",
        "                             google_api_key=os.environ['GOOGLE_API_KEY'])"
      ],
      "metadata": {
        "id": "0JCShBY0cS2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "search_tool = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "G4a-WnsScYfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your agents with roles and goals\n",
        "researcher = Agent(\n",
        "  role='Senior Research Analyst',\n",
        "  goal='Uncover cutting-edge developments in AI and data science',\n",
        "  backstory=\"\"\"You work at a leading tech think tank.\n",
        "  Your expertise lies in identifying emerging trends.\n",
        "  You have a knack for dissecting complex data and presenting\n",
        "  actionable insights.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,\n",
        "  tools=[\n",
        "        search_tool\n",
        "      ])"
      ],
      "metadata": {
        "id": "n0lsfTc5cbv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = Agent(\n",
        "  role='Tech Content Strategist',\n",
        "  goal='Craft compelling content on tech advancements',\n",
        "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
        "  your insightful and engaging articles.\n",
        "  You transform complex concepts into compelling narratives.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,\n",
        "  tools=[]\n",
        ")\n"
      ],
      "metadata": {
        "id": "5M9lEXTvckP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tasks for your agents\n",
        "task1 = Task(\n",
        "  description=\"\"\"Conduct a very quick and simple analysis of the latest advancements in AI in 2024.\n",
        "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
        "  expected_output=\"Full analysis report in bullet points\",\n",
        "  agent=researcher\n",
        ")"
      ],
      "metadata": {
        "id": "VZ8RHXUScslu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "task2 = Task(\n",
        "  description=\"\"\"Using the insights provided, develop an engaging blog\n",
        "  post that highlights the most significant AI advancements.\n",
        "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
        "  Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n",
        "  expected_output=\"A Linkedin post with at least 5 lines\",\n",
        "  agent=writer\n",
        ")"
      ],
      "metadata": {
        "id": "gfHXstEMctTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate your crew with a sequential process\n",
        "crew = Crew(\n",
        "  agents=[researcher, writer],\n",
        "  tasks=[task1, task2],\n",
        "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
        "  process = Process.sequential\n",
        ")\n"
      ],
      "metadata": {
        "id": "VgdYRxjxdBNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your crew to work!\n",
        "result = crew.kickoff()\n",
        "\n",
        "print(\"######################\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y_3SwMQcrTJ",
        "outputId": "a2eece40-6e45-4605-b3e5-e514e8711933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [2024-08-02 04:58:32][DEBUG]: == Working Agent: Senior Research Analyst\u001b[00m\n",
            "\u001b[1m\u001b[95m [2024-08-02 04:58:32][INFO]: == Starting Task: Conduct a very quick and simple analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: duckduckgo_search\n",
            "Action Input: {'query': 'latest advancements in AI in 2024'}\u001b[0m\u001b[95m \n",
            "\n",
            "In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ... Elevating customer service: Why IBM watsonx is the perfect fit for public-facing industries . 4 min read - Artificial intelligence (AI) is augmenting the speed, efficiency and quality of human work. For companies involved in public-facing industries such as travel, education and healthcare, there is a major opportunity to leverage the latest advances in generative and conversational AI. Adobe Stock. It's been a year since OpenAI released ChatGPT, opening the door to seamlessly weave AI into the fabric of our daily lives, propelling industries into the future and even prompting ... Running AI models locally. One of the most significant changes we saw in the second half of 2023 was the arrival of open-source, fully capable small language models that can run on phones, laptops ... The next big thing is AI tools that can do more complex tasks. Here's how they will work. AI tools can be useful for everything from booking flights to translating menus. AlphaProof and ...\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: - Generative AI is becoming more accessible and user-friendly, enabling more people to experiment with AI models.\n",
            "- AI is enhancing customer service, particularly in public-facing industries like travel, education, and healthcare.\n",
            "- Open-source, small language models are empowering users to run AI models locally on devices like phones and laptops.\n",
            "- AI tools are evolving to perform more complex tasks, offering a wide range of applications in various domains.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [2024-08-02 04:58:37][DEBUG]: == [Senior Research Analyst] Task output: - Generative AI is becoming more accessible and user-friendly, enabling more people to experiment with AI models.\n",
            "- AI is enhancing customer service, particularly in public-facing industries like travel, education, and healthcare.\n",
            "- Open-source, small language models are empowering users to run AI models locally on devices like phones and laptops.\n",
            "- AI tools are evolving to perform more complex tasks, offering a wide range of applications in various domains.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [2024-08-02 04:58:37][DEBUG]: == Working Agent: Tech Content Strategist\u001b[00m\n",
            "\u001b[1m\u001b[95m [2024-08-02 04:58:37][INFO]: == Starting Task: Using the insights provided, develop an engaging blog\n",
            "  post that highlights the most significant AI advancements.\n",
            "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
            "  Make it sound cool, avoid complex words so it doesn't sound like AI.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "Final Answer: **Headline: AI Advancements: Unleashing the Future**\n",
            "\n",
            "**Body:**\n",
            "\n",
            "Prepare to be amazed as we delve into the extraordinary world of AI advancements! The future is here, and it's powered by the incredible capabilities of artificial intelligence.\n",
            "\n",
            "From the groundbreaking accessibility of generative AI to the seamless integration of AI in customer service, the possibilities are endless. Open-source language models are empowering individuals to harness the power of AI on their own devices, while AI tools continue to evolve, tackling complex tasks with remarkable efficiency.\n",
            "\n",
            "These advancements are not just confined to research labs; they're already transforming industries. In travel, AI chatbots are providing personalized recommendations and real-time assistance. In education, AI-powered tutoring systems are revolutionizing learning experiences. And in healthcare, AI algorithms are aiding in disease diagnosis and treatment planning.\n",
            "\n",
            "The future of AI is bright, and we're just scratching the surface of its potential. As AI continues to advance, we can expect even more groundbreaking innovations that will shape our world in ways we can only imagine. Stay tuned for the next wave of AI advancements, because the future is here, and it's powered by AI!\n",
            "\n",
            "**#AIAdvancements #GenerativeAI #CustomerServiceAI #OpenSourceAI #AITools**\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [2024-08-02 04:58:43][DEBUG]: == [Tech Content Strategist] Task output: **Headline: AI Advancements: Unleashing the Future**\n",
            "\n",
            "**Body:**\n",
            "\n",
            "Prepare to be amazed as we delve into the extraordinary world of AI advancements! The future is here, and it's powered by the incredible capabilities of artificial intelligence.\n",
            "\n",
            "From the groundbreaking accessibility of generative AI to the seamless integration of AI in customer service, the possibilities are endless. Open-source language models are empowering individuals to harness the power of AI on their own devices, while AI tools continue to evolve, tackling complex tasks with remarkable efficiency.\n",
            "\n",
            "These advancements are not just confined to research labs; they're already transforming industries. In travel, AI chatbots are providing personalized recommendations and real-time assistance. In education, AI-powered tutoring systems are revolutionizing learning experiences. And in healthcare, AI algorithms are aiding in disease diagnosis and treatment planning.\n",
            "\n",
            "The future of AI is bright, and we're just scratching the surface of its potential. As AI continues to advance, we can expect even more groundbreaking innovations that will shape our world in ways we can only imagine. Stay tuned for the next wave of AI advancements, because the future is here, and it's powered by AI!\n",
            "\n",
            "**#AIAdvancements #GenerativeAI #CustomerServiceAI #OpenSourceAI #AITools**\n",
            "\n",
            "\u001b[00m\n",
            "######################\n",
            "**Headline: AI Advancements: Unleashing the Future**\n",
            "\n",
            "**Body:**\n",
            "\n",
            "Prepare to be amazed as we delve into the extraordinary world of AI advancements! The future is here, and it's powered by the incredible capabilities of artificial intelligence.\n",
            "\n",
            "From the groundbreaking accessibility of generative AI to the seamless integration of AI in customer service, the possibilities are endless. Open-source language models are empowering individuals to harness the power of AI on their own devices, while AI tools continue to evolve, tackling complex tasks with remarkable efficiency.\n",
            "\n",
            "These advancements are not just confined to research labs; they're already transforming industries. In travel, AI chatbots are providing personalized recommendations and real-time assistance. In education, AI-powered tutoring systems are revolutionizing learning experiences. And in healthcare, AI algorithms are aiding in disease diagnosis and treatment planning.\n",
            "\n",
            "The future of AI is bright, and we're just scratching the surface of its potential. As AI continues to advance, we can expect even more groundbreaking innovations that will shape our world in ways we can only imagine. Stay tuned for the next wave of AI advancements, because the future is here, and it's powered by AI!\n",
            "\n",
            "**#AIAdvancements #GenerativeAI #CustomerServiceAI #OpenSourceAI #AITools**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motivation"
      ],
      "metadata": {
        "id": "Wn7c5oCRhgSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Andrej Karpathy on Why should work on Agents (2023) - https://www.youtube.com/watch?v=fqVLjtvWgq8"
      ],
      "metadata": {
        "id": "TUhCnOcahc7q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0L0Ut6tedQPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}